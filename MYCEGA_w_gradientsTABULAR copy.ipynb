{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686b464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "calculating on: cuda:0\n",
      "train:shuffel = False\n",
      "eval:shuffel = False\n",
      "Epoch: 0\n",
      "      Training_acc: 0.16286644951140064\n",
      "-------------------\n",
      "\n",
      "Epoch: 1\n",
      "      Training_acc: 0.16286644951140064\n",
      "-------------------\n",
      "\n",
      "NOTE: THESE SAVED MODELS ARE BEEING OVERWRITTEN ON NEXT RUN\n",
      "/home/rosario/explainable/test/Bachelor/\n",
      "evaluating ...\n",
      "Progess: 40.00%\n",
      "test acc: 64.29%\n",
      "test Loss: 0.68\n",
      "-------------------\n",
      "Progess: 90.00%\n",
      "test acc: 64.29%\n",
      "test Loss: 0.67\n",
      "-------------------\n",
      "/home/rosario/explainable/test/Bachelor/\n",
      "/home/rosario/explainable/test/Bachelor/Models\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import train\n",
    "import TorchRandomSeed\n",
    "import modelClass\n",
    "import dataloader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "seed =1\n",
    "seedObject = TorchRandomSeed.TorchRandomSeed(seed=1) \n",
    "\n",
    "with seedObject:\n",
    "    droplist = []#[\"BloodPressure\", \"Pregnancies\", \"Age\", \"SkinThickness\"]\n",
    "    num_epochs = 2\n",
    "    batch_size = 32\n",
    "    test_size = 0.2 # is going to be split again in eval and test\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #dirPath = \"/home/rosario/explainable/Bachelor/\"# root\n",
    "    dirPath= \"/home/rosario/explainable/test/Bachelor/\" \n",
    "\n",
    "    modelsDirPath = dirPath+ \"Models\"\n",
    "\n",
    "    print(\"calculating on: \" +str(device))\n",
    "    lr =0.1 # 0.001 slowed learningrate\n",
    "\n",
    "    # load data\n",
    "  \n",
    "    trainloader ,random_indices_train, testloader,random_indices_test,X_train , X_test,  y_train , y_test, inputFeatures, outputFeatures, datasetName, featureNames= dataloader.load_kaggle_diabetes_dataset(batch_size=batch_size , droplist= droplist)\n",
    "    #trainloader ,random_indices_train, testloader,random_indices_test,X_train , X_test,  y_train , y_test, inputFeatures, outputFeatures, datasetName, featureNames= dataloader.BreastCancerUCI(batch_size= batch_size, droplist=droplist, test_size=test_size)\n",
    "    #trainloader ,random_indices_train, testloader,random_indices_test,X_train , X_test,  y_train , y_test, inputFeatures, outputFeatures, datasetName, featureNames= dataloader.dryBeanUCI(batch_size=batch_size , droplist= droplist)\n",
    "    \n",
    "    #model = modelClass.Net(inputFeatures= inputFeatures, out_features=outputFeatures)\n",
    "    model= modelClass.BinaryClassification2HL64N(inputFeatures= inputFeatures, outputFeatures= outputFeatures)\n",
    "    modelName = model.modelName\n",
    "    \n",
    "    #print(random_indices_test)\n",
    "\n",
    "    #for i,c in testloader:\n",
    "    #    print(i[0])\n",
    "    #    print(X_test[random_indices_test[0]])\n",
    "    #    break\n",
    "    \n",
    "    # Backward Propergation - loss and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    #grads = train.train(trainloader, model, num_epochs, device, y_train,loss_function, optimizer)    \n",
    "    grads =  train.train(trainloader,random_indices_train, testloader,random_indices_test, model, num_epochs, device, y_train, y_test, loss_function, optimizer)\n",
    " \n",
    "    #train.train(trainloader,random_indices_train, testloader,random_indices_test, model, num_epochs, device, y_train, y_test, loss_function, optimizer)\n",
    "    print(dirPath)\n",
    "\n",
    "    import eval\n",
    "    import plotResults\n",
    "    from matplotlib import pyplot as plt\n",
    "    print(\"evaluating ...\")\n",
    "    loaderList = [testloader]\n",
    "    nameList = [\"test\"]\n",
    "    yList = [y_test]\n",
    "    eval.doALLeval(model, modelsDirPath, dirPath, loaderList, device,optimizer, loss_function, num_epochs, nameList, yList, inputFeatures, random_indices_test)\n",
    "    print(dirPath)\n",
    "    print(modelsDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2b7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting...\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n",
      "testSet does only get into consideration for Performance measure to be independet of the explanatory set\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataPath= dirPath+ \"Trainingresults/\"\n",
    "print(\"plotting...\")\n",
    "import utils \n",
    "import numpy as np\n",
    "\n",
    "#unpackedGradiends = utils.unpackingGradients(inputFeatures, grads)\n",
    "#averagedGradientMagnitude = np.average(np.absolute(unpackedGradiends), axis=0) \n",
    "#gradientMagnitudePerFeature = np.absolute(unpackedGradiends)\n",
    "#utils.appendToNPZ(dirPath+ \"data.npz\", \"test\" + \"GradientsPerFeature\", unpackedGradiends)\n",
    "#utils.appendToNPZ(dirPath+ \"data.npz\", \"test\" + \"GradientMagnitudePerFeature\", gradientMagnitudePerFeature)\n",
    "#utils.appendToNPZ(dirPath+ \"data.npz\", \"test\" + \"AveragedGradientMagnitude\", averagedGradientMagnitude)\n",
    "#plotResults.plotCosineSimilarity(dirPath, \"cosine_simialarity\", set=\"train\")\n",
    "#plotResults.plotCosineSimilarity(dirPath, \"cosine_simialarity\", set=\"eval\")\n",
    "plotResults.plotCosineSimilarity(dataPath, \"cosine_simialarity\", set=\"test\")\n",
    "plt.show()\n",
    "#plotResults.plotWeightSignDifferences(dirPath, \"percentageWeightsSignDifference1\" , \"train\")\n",
    "#plotResults.plotWeightSignDifferences(dirPath, \"percentageWeightsSignDifference2\" , \"eval\")\n",
    "plotResults.plotWeightSignDifferences(dataPath, \"percentageWeightsSignDifference3\" , \"test\")\n",
    "plt.show()\n",
    "#plotResults.plotWeightMagnitude(dirPath, \"weightsMagnitude1\",\"train\")\n",
    "#plotResults.plotWeightMagnitude(dirPath, \"weightsMagnitude2\",\"eval\")\n",
    "plotResults.plotWeightMagnitude(dataPath, \"weightsMagnitude3\",\"test\")\n",
    "plt.show()\n",
    "#plotResults.plotL2Distance(dirPath, \"L2Distance1\",\"train\")\n",
    "#plotResults.plotL2Distance(dirPath, \"L2Distance2\",\"eval\")\n",
    "plotResults.plotL2Distance(dataPath, \"L2Distance3\",\"test\")\n",
    "plt.show()\n",
    "#plotResults.plotWeightTrace(dirPath, \"weightTrace1\",\"train\")\n",
    "#plotResults.plotWeightTrace(dirPath, \"weightTrace2\",\"eval\")\n",
    "plotResults.plotWeightTrace(dataPath, \"weightTrace3\",\"test\")    \n",
    "plt.show()\n",
    "#plotResults.plotGradientsPerFeature(dirPath,\"gradientsPerFeature1\" ,False)\n",
    "#plotResults.plotGradientsPerFeature(dirPath,\"gradientsPerFeature2\" ,True )\n",
    "#plt.show()\n",
    "#plotResults.plotGradientMagnitude(dirPath, \"averageGradientMagnitude1\",\"train\", perFeature=False)\n",
    "#plotResults.plotGradientMagnitude(dirPath, \"averageGradientMagnitude2\",\"eval\", perFeature=False)\n",
    "plotResults.plotGradientMagnitude(dataPath, \"averageGradientMagnitude3\",\"test\", perFeature=False)\n",
    "plt.show()\n",
    "#plotResults.plotGradientMagnitude(dirPath, \"GradientMagnitudePerFeature1\",\"train\", perFeature=True)\n",
    "#plotResults.plotGradientMagnitude(dirPath, \"GradientMagnitudePerFeature2\",\"eval\", perFeature=True)\n",
    "plotResults.plotGradientMagnitude(dataPath, \"GradientMagnitudePerFeature3\",\"test\", perFeature=True)\n",
    "plt.show()\n",
    "#plotResults.plotLoss_Acc(dirPath,\"loss_acc1\", False)\n",
    "#plotResults.plotLoss_Acc(dirPath,\"loss_acc2\",True)\n",
    "plt.show()\n",
    "#plotResults.plotConfusionMatrix(dirPath, \"confusionMatrix1\", set=\"train\")\n",
    "#plotResults.plotConfusionMatrix(dirPath, \"confusionMatrix2\", set=\"eval\")\n",
    "plotResults.plotConfusionMatrix(dataPath, \"confusionMatrix3\", set=\"test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5e6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      "inputFeatures\n",
      "testLossPerEpochList\n",
      "testLossPerIterationList\n",
      "testAccPerEpochList\n",
      "testAccPerIterationList\n",
      "testPredictionList\n",
      "testCosine_similarity_toInitialList\n",
      "testCosine_similarity_toFinalList\n",
      "testPercentageWeightSignDifferences_toInitialList\n",
      "testPercentageWeightSignDifferences_toFinalList\n",
      "testAbsoluteIterationWeightsList\n",
      "testL2Dist_toInitialList\n",
      "testL2Dist_toFinalList\n",
      "testRandom10WeightsList\n",
      "testGradientsPerSamplePerFeature\n",
      "testGradientsPerFeature\n",
      "testGradientMagnitudePerFeature\n",
      "testAveragedGradientMagnitude\n",
      "testGradientsPerSamplePerFeature_iteration\n",
      "testGradientsPerFeature_iteration\n",
      "testGradientMagnitudePerFeature_iteration\n",
      "testAveragedGradientMagnitude_iteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 154, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = utils.loadData(dataPath)\n",
    "\n",
    "for i in data:\n",
    "    print(i)\n",
    "\n",
    "np.shape(data[\"testGradientsPerSamplePerFeature_iteration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66ac5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this saves to a dummy folder which is beeing replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:12<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "import cega_utils\n",
    "\n",
    "#data \n",
    "trainedModelPrediction_Test = model.predict(X_test.to(\"cuda:0\"))\n",
    "                                    # data   \n",
    "cega_utils.calculateAndSaveOHE_Rules(X_test, featureNames,trainedModelPrediction_Test, data[\"testGradientsPerSamplePerFeature_iteration\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd10aa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<02:44,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:01<02:33,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:02<02:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:03<02:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:04<02:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:04<02:36,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:05<02:25,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:06<02:30,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:07<02:34,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:07<02:26,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:08<02:33,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:09<02:26,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:10<02:32,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:11<02:28,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:12<02:39,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:13<02:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:14<02:44,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:15<02:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:16<02:53,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:17<03:05,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:18<03:14,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:19<03:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:20<03:16,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:21<03:17,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:23<03:25,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:24<03:19,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [00:25<03:27,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [00:27<03:37,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [00:28<03:35,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [00:29<03:43,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [00:30<03:41,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [00:32<03:48,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [00:33<03:43,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [00:35<03:48,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [00:36<03:42,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [00:38<03:50,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [00:39<03:44,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [00:40<03:52,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [00:42<03:57,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:43<03:53,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:45<04:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [00:47<03:55,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [00:48<04:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [00:50<03:55,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [00:51<03:50,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [00:53<03:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:54<03:49,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:56<03:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [00:57<03:48,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [00:59<03:53,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [01:00<03:50,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [01:02<03:56,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [01:04<03:52,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [01:05<03:59,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [01:07<03:53,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [01:09<03:59,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [01:10<03:54,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [01:12<03:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [01:14<03:57,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [01:15<03:54,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [01:17<03:59,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [01:19<03:53,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [01:21<03:59,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [01:22<03:54,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [01:24<03:52,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [01:26<03:58,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [01:28<03:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [01:30<04:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [01:31<03:55,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [01:33<04:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [01:35<03:56,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [01:37<03:52,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [01:39<03:58,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [01:41<03:54,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [01:43<03:54,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [01:45<04:02,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [01:47<03:56,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [01:49<04:01,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [01:51<03:58,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [01:53<03:53,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [01:55<03:59,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [01:57<03:54,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [01:59<03:58,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [02:01<03:53,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [02:03<03:51,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [02:05<03:57,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [02:07<03:53,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88/200 [02:09<03:57,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [02:11<03:53,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [02:14<03:51,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [02:16<04:01,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92/200 [02:18<04:03,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [02:21<04:01,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [02:23<04:06,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [02:25<04:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [02:28<03:58,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [02:30<04:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/200 [02:32<03:54,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [02:35<03:58,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [02:37<03:51,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [02:39<03:45,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [02:42<03:50,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [02:44<03:45,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#     frequent_itemsets = apriori(basket_sets.astype('bool'), min_support=0.07, use_colnames=True) https://stackoverflow.com/questions/74114745/how-to-fix-deprecationwarning-dataframes-with-non-bool-types-result-in-worse-c\n",
    "debug = True\n",
    "\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "pos_label = '1'\n",
    "neg_label = '0'\n",
    "\n",
    "\n",
    "rulesResultDataPath = dirPath + \"rulesResultData/\" \n",
    "\n",
    "featureDict= {'Pregnancies':0, 'Glucose':1, 'BloodPressure':2, 'SkinThickness':3, 'Insulin':4, \\\n",
    "              'BMI':5, 'DiabetesPedigreeFunction':6, 'Age':7}\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "# Format the date and time as a string\n",
    "date_time_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "discriminative_rules_overIterations = []\n",
    "charachteristic_rules_overIterations = []\n",
    "#\n",
    "rules_list_overIterations   = []\n",
    "labelList_rules_overIterations = []\n",
    "rulePrecisionList_overIterations =[]\n",
    "predictionComparisonList_overIterations = []\n",
    "rulesComplexityList_overIterations = []\n",
    "coverageList_overIterations = []\n",
    "ruleSupportList_overIterations = []\n",
    "numberOfGeneratedRules_overIterations = []\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(os.listdir(\"./OHEresults/\")))):\n",
    "    ohe_df = cega_utils.loadOHE_Rules(i)\n",
    "    all_rules, pos_rules , neg_rules =  cega_utils.runApriori(ohe_df,len(X_test), pos_label ,neg_label)\n",
    "    discriminative_rules = cega_utils.getDiscriminativeRules(all_rules, pos_label, neg_label )\n",
    "    #discriminative_rules\n",
    "    #discriminative_rulesList.append(discriminative_rules)\n",
    "    charachteristic_rules = cega_utils.getCharasteristicRules(pos_rules, pos_label, neg_rules,neg_label )\n",
    "    #charachteristic_rulesList.append(charachteristic_rules)\n",
    "\n",
    "    resultName = \"discriminative_rules\"\n",
    "    rules_list, labelList_rules, rulePrecisionList, predictionComparisonList, rulesComplexityList , coverageList,  ruleSupportList,   numberOfGeneratedRules,  =cega_utils.calculateRulesMetrics(discriminative_rules, resultName ,featureDict, testloader, trainedModelPrediction_Test, rulesResultDataPath, debug=True )\n",
    "    #resultName = \"charachteristic_rules\"\n",
    "    #rules_list, labelList_rules, rulePrecisionList, predictionComparisonList, rulesComplexityList , coverageList,  ruleSupportList,  = numberOfGeneratedRules,  =cega_utils.calculateRulesMetrics(charachteristic_rules, resultName ,featureDict, testloader, trainedModelPrediction_Test, rulesResultDataPath, debug=True )\n",
    "    discriminative_rules_overIterations.append(discriminative_rules)\n",
    "    charachteristic_rules_overIterations.append(charachteristic_rules) \n",
    "    #\n",
    "    rules_list_overIterations.append(rules_list)\n",
    "    labelList_rules_overIterations.append(labelList_rules)\n",
    "    rulePrecisionList_overIterations.append(rulePrecisionList)\n",
    "    predictionComparisonList_overIterations.append(predictionComparisonList)\n",
    "    rulesComplexityList_overIterations.append(rulesComplexityList)\n",
    "    coverageList_overIterations.append(coverageList)\n",
    "    ruleSupportList_overIterations.append(ruleSupportList)\n",
    "    numberOfGeneratedRules_overIterations.append(numberOfGeneratedRules)\n",
    "\n",
    "print(\"joo\")\n",
    "if debug:\n",
    "    pathToNPZ =  dirPath + f\"DEBUG.npz\"\n",
    "    print(pathToNPZ)\n",
    "else:    \n",
    "    pathToNPZ =  dirPath + f\"{resultName}_{date_time_string}.npz\"\n",
    "np.savez(pathToNPZ ,rules_list_overIterations = rules_list_overIterations) \n",
    "utils.appendToNPZ(pathToNPZ, \"labelList_rules_overIterations\", labelList_rules_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"rulePrecisionList_overIterations\", rulePrecisionList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"predictionComparisonList_overIterations\", predictionComparisonList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"rulesComplexityList_overIterations\", rulesComplexityList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"coverageList_overIterations\", coverageList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"ruleSupportList_overIterations\", ruleSupportList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"numberOfGeneratedRules_overIterations\", numberOfGeneratedRules_overIterations)\n",
    "\n",
    "#utils.appendToNPZ(rules_data)\n",
    "    #charachteristic_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ce4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in t range(len(os.listdir(\"./OHEresults/\"))):\n",
    "    ohe_df = cega_utils.loadOHE_Rules(i)\n",
    "    all_rules, pos_rules , neg_rules =  cega_utils.runApriori(ohe_df,len(X_test), pos_label ,neg_label)\n",
    "    discriminative_rules = cega_utils.getDiscriminativeRules(all_rules, pos_label, neg_label )\n",
    "    #discriminative_rules\n",
    "    #discriminative_rulesList.append(discriminative_rules)\n",
    "    charachteristic_rules = cega_utils.getCharasteristicRules(pos_rules, pos_label, neg_rules,neg_label )\n",
    "    #charachteristic_rulesList.append(charachteristic_rules)\n",
    "\n",
    "    resultName = \"discriminative_rules\"\n",
    "    rules_list, labelList_rules, rulePrecisionList, predictionComparisonList, rulesComplexityList , coverageList,  ruleSupportList,   numberOfGeneratedRules,  =cega_utils.calculateRulesMetrics(discriminative_rules, resultName ,featureDict, testloader, trainedModelPrediction_Test, rulesResultDataPath, debug=True )\n",
    "    #resultName = \"charachteristic_rules\"\n",
    "    #rules_list, labelList_rules, rulePrecisionList, predictionComparisonList, rulesComplexityList , coverageList,  ruleSupportList,  = numberOfGeneratedRules,  =cega_utils.calculateRulesMetrics(charachteristic_rules, resultName ,featureDict, testloader, trainedModelPrediction_Test, rulesResultDataPath, debug=True )\n",
    "    debug = True\n",
    "    discriminative_rules_overIterations.append(discriminative_rules)\n",
    "    charachteristic_rules_overIterations.append(charachteristic_rules) \n",
    "    #\n",
    "    rules_list_overIterations.append(rules_list)\n",
    "    labelList_rules_overIterations.append(labelList_rules)\n",
    "    rulePrecisionList_overIterations.append(rulePrecisionList)\n",
    "    predictionComparisonList_overIterations.append(predictionComparisonList)\n",
    "    rulesComplexityList_overIterations.append(rulesComplexityList)\n",
    "    coverageList_overIterations.append(coverageList)\n",
    "    ruleSupportList_overIterations.append(ruleSupportList)\n",
    "    numberOfGeneratedRules_overIterations.append(numberOfGeneratedRules)\n",
    "\n",
    "if debug:\n",
    "    pathToNPZ =  dirPath + f\"DEBUG.npz\"\n",
    "else:    \n",
    "    pathToNPZ =  dirPath + f\"{resultName}_{date_time_string}.npz\"\n",
    "np.savez(pathToNPZ ,rules_list = rules_list) \n",
    "utils.appendToNPZ(pathToNPZ, \"labelList_rules_overIterations\", labelList_rules_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"rulePrecisionList_overIterations\", rulePrecisionList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"predictionComparisonList_overIterations\", predictionComparisonList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"rulesComplexityList_overIterations\", rulesComplexityList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"coverageList_overIterations\", coverageList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"ruleSupportList_overIterations\", ruleSupportList_overIterations)\n",
    "utils.appendToNPZ(pathToNPZ, \"numberOfGeneratedRules_overIterations\", numberOfGeneratedRules_overIterations)\n",
    "\n",
    "#utils.appendToNPZ(rules_data)\n",
    "    #charachteristic_rules\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1c0ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>itemset</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>consequent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, itemset, num-items, support, confidence, consequent support]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charachteristic_rules = cega_utils.getCharasteristicRules(pos_rules, pos_label, neg_rules,neg_label )\n",
    "charachteristic_rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f73926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rosario/explainable/Bachelor/rulesResultData/\n"
     ]
    }
   ],
   "source": [
    "featureDict= {'Pregnancies':0, 'Glucose':1, 'BloodPressure':2, 'SkinThickness':3, 'Insulin':4,\n",
    "                                        'BMI':5, 'DiabetesPedigreeFunction':6, 'Age':7}\n",
    "rulesResultDataPath = dirPath + \"rulesResultData/\" \n",
    "\n",
    "resultName = \"charachteristic_rules\"\n",
    "\n",
    "rules_list, labelList_rules, rulePrecisionList, predictionComparisonList, rulesComplexityList , coverageList,  ruleSupportList,  = numberOfGeneratedRules,  =cega_utils.calculateRulesMetrics(charachteristic_rules, resultName ,featureDict, testloader, trainedModelPrediction_Test, rulesResultDataPath, debug=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "437e8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rules_list\n",
      "labelList_rules_overIterations\n",
      "rulePrecisionList_overIterations\n",
      "predictionComparisonList_overIterations\n",
      "rulesComplexityList_overIterations\n",
      "coverageList_overIterations\n",
      "ruleSupportList_overIterations\n",
      "numberOfGeneratedRules_overIterations\n"
     ]
    }
   ],
   "source": [
    "rules_data = np.load(pathToNPZ , allow_pickle=True)\n",
    "\n",
    "for i in rules_data:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grads\n",
    "grads1 = data[\"testGradientsPerSamplePerFeature_iteration\"]\n",
    "grads2 = data[\"testGradientsPerFeature_iteration\"]\n",
    "grads3 = data[\"testGradientsPerSamplePerFeature\"]\n",
    "grads4 = data[\"testGradientsPerFeature\"]\n",
    "\n",
    "\n",
    "\n",
    "#print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef76205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 154, 8)\n",
      "(8, 6160)\n",
      "(2, 154, 8)\n",
      "(8, 308)\n",
      "\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n",
      "(154, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "gradsOLDTRAIN = grads\n",
    "#print(np.shape(grads) ) #epochs, num samples , features\n",
    "print(np.shape(grads1) )# trainingsIterationen (Epochen* iteratipnProEpoche) , numsamples , numfeatures  \n",
    "print(np.shape(grads2) ) # gradients unpacked for each iteration [grads1 unpacked] # \n",
    "print(np.shape(grads3) ) # trainingsEpochen , numsamples , numfeatures\n",
    "print(np.shape(grads4) ) #gradients unpacked for each Epoch \n",
    "print()\n",
    "\n",
    "for i in grads1:\n",
    "    print(np.shape(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c297c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 154, 8)\n"
     ]
    }
   ],
   "source": [
    "grads =  grads1\n",
    "print(np.shape(grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5abd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 154, 8)\n",
      "(154, 8)\n",
      "[[-9.3162380e-04 -3.2841815e-03 -8.3877334e-05 ...  2.4605729e-03\n",
      "   1.9583183e-03  5.8975205e-04]\n",
      " [ 5.4750271e-04 -1.1041617e-03  6.8767171e-04 ...  4.5737787e-03\n",
      "   4.4620959e-03  1.8397891e-03]\n",
      " [ 1.1752852e-03 -2.5347152e-03  3.9854078e-04 ...  5.2994373e-03\n",
      "   4.0180185e-03  6.9511111e-04]\n",
      " ...\n",
      " [ 8.4036012e-04 -1.6429188e-03  4.9080094e-04 ...  4.8838374e-03\n",
      "   5.2968962e-03  2.7640860e-03]\n",
      " [ 3.8396640e-04 -2.8041452e-03 -6.5994798e-04 ...  3.9295400e-03\n",
      "   5.2804509e-03  2.3647344e-03]\n",
      " [ 1.6338422e-03 -2.0254145e-03 -1.2722553e-03 ...  5.1425421e-03\n",
      "   4.1813711e-03  3.8768095e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#print(grads)\n",
    "#for i in grads:\n",
    "#    print(np.shape(i))\n",
    "#oldGrads = grads\n",
    "#grads = grads[299:300]\n",
    "##grads_forEachSample = np.concatenate(grads, axis=0).reshape(-1, 8)\n",
    "#print(np.shape(grads_forEachSample))\n",
    "\n",
    "print(np.shape(grads))\n",
    "print(np.shape(grads[0]))\n",
    "print(grads[0]) #epochs , # sampleSize , #batchsize , #input_featuresize\n",
    "\n",
    "#print(int(len(grads_forEachSample)/ batch_size))\n",
    "#grads_forEachSample.reshape(int(len(grads_forEachSample)/ batch_size) , batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21750c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cores: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.928856</td>\n",
       "      <td>1.469709</td>\n",
       "      <td>0.316910</td>\n",
       "      <td>-0.575579</td>\n",
       "      <td>1.451115</td>\n",
       "      <td>-0.575579</td>\n",
       "      <td>-1.046981</td>\n",
       "      <td>-0.110741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.603717</td>\n",
       "      <td>2.267948</td>\n",
       "      <td>0.525804</td>\n",
       "      <td>-0.622862</td>\n",
       "      <td>-0.622862</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-0.619435</td>\n",
       "      <td>-0.201684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.698853</td>\n",
       "      <td>2.093766</td>\n",
       "      <td>0.765239</td>\n",
       "      <td>-0.129484</td>\n",
       "      <td>-0.861530</td>\n",
       "      <td>-0.183710</td>\n",
       "      <td>-0.855945</td>\n",
       "      <td>-0.129484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.951097</td>\n",
       "      <td>0.962289</td>\n",
       "      <td>1.655067</td>\n",
       "      <td>-0.126362</td>\n",
       "      <td>-1.050066</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>-1.042049</td>\n",
       "      <td>0.467448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.910719</td>\n",
       "      <td>0.920288</td>\n",
       "      <td>0.315260</td>\n",
       "      <td>-0.464909</td>\n",
       "      <td>1.939283</td>\n",
       "      <td>-0.351864</td>\n",
       "      <td>-0.918744</td>\n",
       "      <td>-0.528596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.958410</td>\n",
       "      <td>1.900715</td>\n",
       "      <td>0.701727</td>\n",
       "      <td>-0.558748</td>\n",
       "      <td>0.517267</td>\n",
       "      <td>-0.315876</td>\n",
       "      <td>-1.127591</td>\n",
       "      <td>-0.159085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-1.001330</td>\n",
       "      <td>1.212592</td>\n",
       "      <td>0.244001</td>\n",
       "      <td>-0.289713</td>\n",
       "      <td>1.706771</td>\n",
       "      <td>-0.307503</td>\n",
       "      <td>-1.057667</td>\n",
       "      <td>-0.507151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.584841</td>\n",
       "      <td>2.212725</td>\n",
       "      <td>0.503101</td>\n",
       "      <td>-0.709177</td>\n",
       "      <td>-0.709177</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>-0.707048</td>\n",
       "      <td>-0.040870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.601401</td>\n",
       "      <td>1.893327</td>\n",
       "      <td>0.864966</td>\n",
       "      <td>-0.696620</td>\n",
       "      <td>-0.696620</td>\n",
       "      <td>-0.696620</td>\n",
       "      <td>-0.684432</td>\n",
       "      <td>0.617398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.483761</td>\n",
       "      <td>2.253082</td>\n",
       "      <td>-0.611056</td>\n",
       "      <td>-0.611056</td>\n",
       "      <td>-0.611056</td>\n",
       "      <td>0.280009</td>\n",
       "      <td>-0.591643</td>\n",
       "      <td>0.375480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI   \n",
       "0      -0.928856  1.469709       0.316910      -0.575579  1.451115 -0.575579  \\\n",
       "1      -0.603717  2.267948       0.525804      -0.622862 -0.622862 -0.123192   \n",
       "2      -0.698853  2.093766       0.765239      -0.129484 -0.861530 -0.183710   \n",
       "3      -0.951097  0.962289       1.655067      -0.126362 -1.050066  0.084771   \n",
       "4      -0.910719  0.920288       0.315260      -0.464909  1.939283 -0.351864   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "149    -0.958410  1.900715       0.701727      -0.558748  0.517267 -0.315876   \n",
       "150    -1.001330  1.212592       0.244001      -0.289713  1.706771 -0.307503   \n",
       "151    -0.584841  2.212725       0.503101      -0.709177 -0.709177  0.035286   \n",
       "152    -0.601401  1.893327       0.864966      -0.696620 -0.696620 -0.696620   \n",
       "153    -0.483761  2.253082      -0.611056      -0.611056 -0.611056  0.280009   \n",
       "\n",
       "     DiabetesPedigreeFunction       Age  \n",
       "0                   -1.046981 -0.110741  \n",
       "1                   -0.619435 -0.201684  \n",
       "2                   -0.855945 -0.129484  \n",
       "3                   -1.042049  0.467448  \n",
       "4                   -0.918744 -0.528596  \n",
       "..                        ...       ...  \n",
       "149                 -1.127591 -0.159085  \n",
       "150                 -1.057667 -0.507151  \n",
       "151                 -0.707048 -0.040870  \n",
       "152                 -0.684432  0.617398  \n",
       "153                 -0.591643  0.375480  \n",
       "\n",
       "[154 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count, Queue\n",
    "from helper_func import *\n",
    "import pandas as pd\n",
    "\n",
    "X_test_DF = pd.DataFrame(X_test, columns=featureNames)\n",
    "num_cores = cpu_count()\n",
    "print(f'num of cores: {num_cores}')\n",
    "#print(X_train)\n",
    "if len(intervals_dict) == 0:\n",
    "        compute_intervals(intervals_dict, X_test_DF)\n",
    "\n",
    "#print(intervals_dict)\n",
    "X_test_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b2b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:05<00:00,  6.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "#import shutil\n",
    "\n",
    "pred = model.predict(X_test.to(\"cuda:0\"))\n",
    "\n",
    "#print(pred)\n",
    "#print(clf.predict_proba)\n",
    "#print(pred)\n",
    "pos_label = '1'\n",
    "neg_label = '0'\n",
    "\n",
    "itemset = set()\n",
    "encoded_vals = []\n",
    "#summed_values = {}\n",
    "#num_features = X_train.shape[1]\n",
    "\n",
    "shap_threshold = 0.001\n",
    "\n",
    "p = Pool(num_cores)\n",
    "\n",
    "for feature in X_test_DF.columns.to_list(): # for NLP this must be the whole vocab \n",
    "    if feature in intervals_dict:\n",
    "        intervals = intervals_dict[feature]\n",
    "        for interval in intervals:\n",
    "            if interval != interval: continue\n",
    "            left = interval.left\n",
    "            right = interval.right\n",
    "            name = f'{left}<{feature}<={right}'\n",
    "            itemset.add(name)\n",
    "    else:\n",
    "        itemset.add(feature)\n",
    "\n",
    "itemset.add(pos_label)\n",
    "itemset.add(neg_label)\n",
    "\n",
    "#for batch in tqdm(grads):\n",
    "#    for sample in batch:\n",
    "#ohe_dfList = [] \n",
    "\n",
    "def CEGA(epoch): \n",
    "    #print(np.shape(epoch))\n",
    "    for indx in range(len(epoch)):#for indx in range(len(pred)):\n",
    "        pos_queue.put(pos_label)\n",
    "        neg_queue.put(neg_label)\n",
    "        exp = epoch[indx]#[item[indx] for item in sample] #normalize featureListALL ?\n",
    "        #print(\"exp\")\n",
    "        #print(np.shape(exp))\n",
    "        #print(exp)\n",
    "        \n",
    "        instance_features = X_test_DF.iloc[[indx]].to_dict(orient='records')[0]\n",
    "        feature_vals = [instance_features[name] for name in featureNames] #put here grads# feature values ?? \n",
    "\n",
    "        # GRADS AS LOCAL EXPLAINATION #\n",
    "        # \n",
    "        #print(\"eh\")\n",
    "\n",
    "        zipped = zip(exp, feature_vals,\n",
    "                     featureNames, [shap_threshold]*len(featureNames))\n",
    "\n",
    "\n",
    "        p.map(get_relevant_features, zipped)\n",
    "        append_to_encoded_vals(pos_queue, itemset, encoded_vals)\n",
    "        append_to_encoded_vals(neg_queue, itemset, encoded_vals)\n",
    "\n",
    "        ohe_df = pd.DataFrame(encoded_vals)\n",
    "        #print(ohe_df)\n",
    "        #exit()\n",
    "    return ohe_df #ohe_dfList.append(ohe_df)\n",
    "\n",
    "\n",
    "output_directory = './DEBUG/OHEresults/'\n",
    "output_base_filename = 'ohe@Iteration'\n",
    "counter = 0\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "for i in tqdm (range(len(grads))):\n",
    "\n",
    "    epoch  = grads[i]\n",
    "    output_filename = f'{output_directory}{output_base_filename}_{counter}.pkl'\n",
    "    try:\n",
    "        with open(output_filename, 'xb') as f:\n",
    "            ohe_df = CEGA(epoch)\n",
    "            pickle.dump(ohe_df, f)\n",
    "            counter += 1\n",
    "    except FileExistsError:\n",
    "        # If the file already exists, increment the counter and try again\n",
    "        counter += 1\n",
    "# TAKES ~30 sec for 154 samples  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1.074&lt;DiabetesPedigreeFunction&lt;=-0.864</th>\n",
       "      <th>-0.583&lt;BMI&lt;=-0.292</th>\n",
       "      <th>-0.292&lt;BMI&lt;=-0.00171</th>\n",
       "      <th>-0.942&lt;Glucose&lt;=-0.271</th>\n",
       "      <th>1.731&lt;Glucose&lt;=2.399</th>\n",
       "      <th>0.14&lt;Age&lt;=0.396</th>\n",
       "      <th>-0.398&lt;Insulin&lt;=0.297</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.493&lt;DiabetesPedigreeFunction&lt;=-1.283</th>\n",
       "      <th>-0.778&lt;Pregnancies&lt;=-0.583</th>\n",
       "      <th>...</th>\n",
       "      <th>1.429&lt;BloodPressure&lt;=1.943</th>\n",
       "      <th>-0.543&lt;SkinThickness&lt;=-0.249</th>\n",
       "      <th>-0.655&lt;DiabetesPedigreeFunction&lt;=-0.445</th>\n",
       "      <th>-0.627&lt;BloodPressure&lt;=-0.111</th>\n",
       "      <th>0.396&lt;Glucose&lt;=1.064</th>\n",
       "      <th>-0.864&lt;DiabetesPedigreeFunction&lt;=-0.655</th>\n",
       "      <th>1.064&lt;Glucose&lt;=1.731</th>\n",
       "      <th>-0.111&lt;BloodPressure&lt;=0.403</th>\n",
       "      <th>0.992&lt;Insulin&lt;=1.687</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -1.074<DiabetesPedigreeFunction<=-0.864  -0.583<BMI<=-0.292   \n",
       "0                                          0                   0  \\\n",
       "1                                          1                   1   \n",
       "2                                          0                   0   \n",
       "3                                          0                   0   \n",
       "4                                          0                   0   \n",
       "..                                       ...                 ...   \n",
       "303                                        0                   0   \n",
       "304                                        0                   0   \n",
       "305                                        0                   0   \n",
       "306                                        0                   0   \n",
       "307                                        0                   0   \n",
       "\n",
       "     -0.292<BMI<=-0.00171  -0.942<Glucose<=-0.271  1.731<Glucose<=2.399   \n",
       "0                       0                       0                     0  \\\n",
       "1                       0                       0                     0   \n",
       "2                       0                       0                     1   \n",
       "3                       1                       0                     0   \n",
       "4                       0                       0                     1   \n",
       "..                    ...                     ...                   ...   \n",
       "303                     0                       0                     0   \n",
       "304                     0                       0                     1   \n",
       "305                     0                       0                     0   \n",
       "306                     0                       0                     1   \n",
       "307                     0                       0                     0   \n",
       "\n",
       "     0.14<Age<=0.396  -0.398<Insulin<=0.297  0   \n",
       "0                  0                      0  0  \\\n",
       "1                  0                      0  1   \n",
       "2                  0                      0  0   \n",
       "3                  0                      0  1   \n",
       "4                  0                      0  0   \n",
       "..               ...                    ... ..   \n",
       "303                0                      0  1   \n",
       "304                0                      0  0   \n",
       "305                0                      0  1   \n",
       "306                1                      0  0   \n",
       "307                0                      0  1   \n",
       "\n",
       "     -1.493<DiabetesPedigreeFunction<=-1.283  -0.778<Pregnancies<=-0.583  ...   \n",
       "0                                          0                           0  ...  \\\n",
       "1                                          0                           0  ...   \n",
       "2                                          0                           0  ...   \n",
       "3                                          0                           1  ...   \n",
       "4                                          0                           0  ...   \n",
       "..                                       ...                         ...  ...   \n",
       "303                                        0                           1  ...   \n",
       "304                                        0                           0  ...   \n",
       "305                                        0                           1  ...   \n",
       "306                                        0                           0  ...   \n",
       "307                                        0                           0  ...   \n",
       "\n",
       "     1.429<BloodPressure<=1.943  -0.543<SkinThickness<=-0.249   \n",
       "0                             0                             0  \\\n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "..                          ...                           ...   \n",
       "303                           0                             0   \n",
       "304                           0                             0   \n",
       "305                           0                             0   \n",
       "306                           0                             0   \n",
       "307                           0                             0   \n",
       "\n",
       "     -0.655<DiabetesPedigreeFunction<=-0.445  -0.627<BloodPressure<=-0.111   \n",
       "0                                          0                             0  \\\n",
       "1                                          0                             0   \n",
       "2                                          0                             0   \n",
       "3                                          1                             0   \n",
       "4                                          0                             0   \n",
       "..                                       ...                           ...   \n",
       "303                                        0                             0   \n",
       "304                                        0                             0   \n",
       "305                                        0                             0   \n",
       "306                                        0                             1   \n",
       "307                                        1                             0   \n",
       "\n",
       "     0.396<Glucose<=1.064  -0.864<DiabetesPedigreeFunction<=-0.655   \n",
       "0                       0                                        0  \\\n",
       "1                       0                                        0   \n",
       "2                       0                                        0   \n",
       "3                       0                                        0   \n",
       "4                       0                                        0   \n",
       "..                    ...                                      ...   \n",
       "303                     0                                        1   \n",
       "304                     0                                        0   \n",
       "305                     0                                        1   \n",
       "306                     0                                        0   \n",
       "307                     0                                        0   \n",
       "\n",
       "     1.064<Glucose<=1.731  -0.111<BloodPressure<=0.403  0.992<Insulin<=1.687   \n",
       "0                       1                            1                     1  \\\n",
       "1                       0                            0                     0   \n",
       "2                       0                            0                     0   \n",
       "3                       0                            0                     0   \n",
       "4                       0                            0                     0   \n",
       "..                    ...                          ...                   ...   \n",
       "303                     0                            0                     0   \n",
       "304                     0                            0                     0   \n",
       "305                     0                            0                     0   \n",
       "306                     0                            0                     0   \n",
       "307                     0                            0                     0   \n",
       "\n",
       "     1  \n",
       "0    1  \n",
       "1    0  \n",
       "2    1  \n",
       "3    0  \n",
       "4    1  \n",
       "..  ..  \n",
       "303  0  \n",
       "304  1  \n",
       "305  0  \n",
       "306  1  \n",
       "307  0  \n",
       "\n",
       "[308 rows x 42 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "path  = \"./OHEresults/ohe@Iteration_0.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    ohe_df =  pickle.load(f)\n",
    "\n",
    "ohe_df\n",
    "\n",
    "#ohe_dfList[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fc30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1.074&lt;DiabetesPedigreeFunction&lt;=-0.864</th>\n",
       "      <th>-0.583&lt;BMI&lt;=-0.292</th>\n",
       "      <th>-0.292&lt;BMI&lt;=-0.00171</th>\n",
       "      <th>-0.942&lt;Glucose&lt;=-0.271</th>\n",
       "      <th>1.731&lt;Glucose&lt;=2.399</th>\n",
       "      <th>0.14&lt;Age&lt;=0.396</th>\n",
       "      <th>-0.398&lt;Insulin&lt;=0.297</th>\n",
       "      <th>0</th>\n",
       "      <th>-1.493&lt;DiabetesPedigreeFunction&lt;=-1.283</th>\n",
       "      <th>-0.778&lt;Pregnancies&lt;=-0.583</th>\n",
       "      <th>...</th>\n",
       "      <th>1.429&lt;BloodPressure&lt;=1.943</th>\n",
       "      <th>-0.543&lt;SkinThickness&lt;=-0.249</th>\n",
       "      <th>-0.655&lt;DiabetesPedigreeFunction&lt;=-0.445</th>\n",
       "      <th>-0.627&lt;BloodPressure&lt;=-0.111</th>\n",
       "      <th>0.396&lt;Glucose&lt;=1.064</th>\n",
       "      <th>-0.864&lt;DiabetesPedigreeFunction&lt;=-0.655</th>\n",
       "      <th>1.064&lt;Glucose&lt;=1.731</th>\n",
       "      <th>-0.111&lt;BloodPressure&lt;=0.403</th>\n",
       "      <th>0.992&lt;Insulin&lt;=1.687</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -1.074<DiabetesPedigreeFunction<=-0.864  -0.583<BMI<=-0.292   \n",
       "0                                          0                   0  \\\n",
       "1                                          1                   1   \n",
       "2                                          0                   0   \n",
       "3                                          0                   0   \n",
       "4                                          0                   0   \n",
       "..                                       ...                 ...   \n",
       "303                                        0                   0   \n",
       "304                                        0                   0   \n",
       "305                                        0                   0   \n",
       "306                                        0                   0   \n",
       "307                                        0                   0   \n",
       "\n",
       "     -0.292<BMI<=-0.00171  -0.942<Glucose<=-0.271  1.731<Glucose<=2.399   \n",
       "0                       0                       0                     0  \\\n",
       "1                       0                       0                     0   \n",
       "2                       0                       0                     1   \n",
       "3                       1                       0                     0   \n",
       "4                       0                       0                     1   \n",
       "..                    ...                     ...                   ...   \n",
       "303                     0                       0                     0   \n",
       "304                     0                       0                     1   \n",
       "305                     0                       0                     0   \n",
       "306                     0                       0                     1   \n",
       "307                     0                       0                     0   \n",
       "\n",
       "     0.14<Age<=0.396  -0.398<Insulin<=0.297  0   \n",
       "0                  0                      0  0  \\\n",
       "1                  0                      0  1   \n",
       "2                  0                      0  0   \n",
       "3                  0                      0  1   \n",
       "4                  0                      0  0   \n",
       "..               ...                    ... ..   \n",
       "303                0                      0  1   \n",
       "304                0                      0  0   \n",
       "305                0                      0  1   \n",
       "306                1                      0  0   \n",
       "307                0                      0  1   \n",
       "\n",
       "     -1.493<DiabetesPedigreeFunction<=-1.283  -0.778<Pregnancies<=-0.583  ...   \n",
       "0                                          0                           0  ...  \\\n",
       "1                                          0                           0  ...   \n",
       "2                                          0                           0  ...   \n",
       "3                                          0                           1  ...   \n",
       "4                                          0                           0  ...   \n",
       "..                                       ...                         ...  ...   \n",
       "303                                        0                           1  ...   \n",
       "304                                        0                           0  ...   \n",
       "305                                        0                           1  ...   \n",
       "306                                        0                           0  ...   \n",
       "307                                        0                           0  ...   \n",
       "\n",
       "     1.429<BloodPressure<=1.943  -0.543<SkinThickness<=-0.249   \n",
       "0                             0                             0  \\\n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "..                          ...                           ...   \n",
       "303                           0                             0   \n",
       "304                           0                             0   \n",
       "305                           0                             0   \n",
       "306                           0                             0   \n",
       "307                           0                             0   \n",
       "\n",
       "     -0.655<DiabetesPedigreeFunction<=-0.445  -0.627<BloodPressure<=-0.111   \n",
       "0                                          0                             0  \\\n",
       "1                                          0                             0   \n",
       "2                                          0                             0   \n",
       "3                                          1                             0   \n",
       "4                                          0                             0   \n",
       "..                                       ...                           ...   \n",
       "303                                        0                             0   \n",
       "304                                        0                             0   \n",
       "305                                        0                             0   \n",
       "306                                        0                             1   \n",
       "307                                        1                             0   \n",
       "\n",
       "     0.396<Glucose<=1.064  -0.864<DiabetesPedigreeFunction<=-0.655   \n",
       "0                       0                                        0  \\\n",
       "1                       0                                        0   \n",
       "2                       0                                        0   \n",
       "3                       0                                        0   \n",
       "4                       0                                        0   \n",
       "..                    ...                                      ...   \n",
       "303                     0                                        1   \n",
       "304                     0                                        0   \n",
       "305                     0                                        1   \n",
       "306                     0                                        0   \n",
       "307                     0                                        0   \n",
       "\n",
       "     1.064<Glucose<=1.731  -0.111<BloodPressure<=0.403  0.992<Insulin<=1.687   \n",
       "0                       1                            1                     1  \\\n",
       "1                       0                            0                     0   \n",
       "2                       0                            0                     0   \n",
       "3                       0                            0                     0   \n",
       "4                       0                            0                     0   \n",
       "..                    ...                          ...                   ...   \n",
       "303                     0                            0                     0   \n",
       "304                     0                            0                     0   \n",
       "305                     0                            0                     0   \n",
       "306                     0                            0                     0   \n",
       "307                     0                            0                     0   \n",
       "\n",
       "     1  \n",
       "0    1  \n",
       "1    0  \n",
       "2    1  \n",
       "3    0  \n",
       "4    1  \n",
       "..  ..  \n",
       "303  0  \n",
       "304  1  \n",
       "305  0  \n",
       "306  1  \n",
       "307  0  \n",
       "\n",
       "[308 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c75966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosario/.local/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/home/rosario/.local/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/home/rosario/.local/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         antecedents   \n",
      "0                                  (0.14<Age<=0.396)  \\\n",
      "1                             (1.731<Glucose<=2.399)   \n",
      "2                                  (0.289<BMI<=0.58)   \n",
      "3                                 (-0.116<Age<=0.14)   \n",
      "4                             (1.731<Glucose<=2.399)   \n",
      "..                                               ...   \n",
      "924  (-0.627<BloodPressure<=-0.111, 0.14<Age<=0.396)   \n",
      "925                             (1, 0.14<Age<=0.396)   \n",
      "926                                (0.289<BMI<=0.58)   \n",
      "927                   (-0.627<BloodPressure<=-0.111)   \n",
      "928                                (0.14<Age<=0.396)   \n",
      "\n",
      "                                           consequents  antecedent support   \n",
      "0                               (1.731<Glucose<=2.399)            0.064935  \\\n",
      "1                                    (0.14<Age<=0.396)            0.474026   \n",
      "2                               (1.731<Glucose<=2.399)            0.006494   \n",
      "3                               (1.731<Glucose<=2.399)            0.077922   \n",
      "4                                   (-0.116<Age<=0.14)            0.474026   \n",
      "..                                                 ...                 ...   \n",
      "924         (0.289<BMI<=0.58, 1, 1.731<Glucose<=2.399)            0.025974   \n",
      "925  (0.289<BMI<=0.58, -0.627<BloodPressure<=-0.111...            0.064935   \n",
      "926  (-0.627<BloodPressure<=-0.111, 0.14<Age<=0.396...            0.006494   \n",
      "927  (0.289<BMI<=0.58, 0.14<Age<=0.396, 1, 1.731<Gl...            0.084416   \n",
      "928  (0.289<BMI<=0.58, -0.627<BloodPressure<=-0.111...            0.064935   \n",
      "\n",
      "     consequent support   support  confidence       lift  leverage  conviction  \n",
      "0              0.474026  0.051948    0.800000   1.687671  0.021167    2.629870  \n",
      "1              0.064935  0.051948    0.109589   1.687671  0.021167    1.050150  \n",
      "2              0.474026  0.006494    1.000000   2.109589  0.003415         inf  \n",
      "3              0.474026  0.058442    0.750000   1.582192  0.021504    2.103896  \n",
      "4              0.077922  0.058442    0.123288   1.582192  0.021504    1.051745  \n",
      "..                  ...       ...         ...        ...       ...         ...  \n",
      "924            0.006494  0.006494    0.250000  38.500000  0.006325    1.324675  \n",
      "925            0.006494  0.006494    0.100000  15.400000  0.006072    1.103896  \n",
      "926            0.025974  0.006494    1.000000  38.500000  0.006325         inf  \n",
      "927            0.006494  0.006494    0.076923  11.846154  0.005945    1.076299  \n",
      "928            0.006494  0.006494    0.100000  15.400000  0.006072    1.103896  \n",
      "\n",
      "[929 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.687671</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>2.629870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>(0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>1.687671</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>1.050150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58)</td>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.109589</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.582192</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>2.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>1.582192</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>1.051745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111, 0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58, 1, 1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>1.324675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>(1, 0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58, -0.627&lt;BloodPressure&lt;=-0.111...</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>1.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58)</td>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111, 0.14&lt;Age&lt;=0.396...</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111)</td>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58, 0.14&lt;Age&lt;=0.396, 1, 1.731&lt;Gl...</td>\n",
       "      <td>0.084416</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>11.846154</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>1.076299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>(0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58, -0.627&lt;BloodPressure&lt;=-0.111...</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>1.103896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         antecedents   \n",
       "0                                  (0.14<Age<=0.396)  \\\n",
       "1                             (1.731<Glucose<=2.399)   \n",
       "2                                  (0.289<BMI<=0.58)   \n",
       "3                                 (-0.116<Age<=0.14)   \n",
       "4                             (1.731<Glucose<=2.399)   \n",
       "..                                               ...   \n",
       "924  (-0.627<BloodPressure<=-0.111, 0.14<Age<=0.396)   \n",
       "925                             (1, 0.14<Age<=0.396)   \n",
       "926                                (0.289<BMI<=0.58)   \n",
       "927                   (-0.627<BloodPressure<=-0.111)   \n",
       "928                                (0.14<Age<=0.396)   \n",
       "\n",
       "                                           consequents  antecedent support   \n",
       "0                               (1.731<Glucose<=2.399)            0.064935  \\\n",
       "1                                    (0.14<Age<=0.396)            0.474026   \n",
       "2                               (1.731<Glucose<=2.399)            0.006494   \n",
       "3                               (1.731<Glucose<=2.399)            0.077922   \n",
       "4                                   (-0.116<Age<=0.14)            0.474026   \n",
       "..                                                 ...                 ...   \n",
       "924         (0.289<BMI<=0.58, 1, 1.731<Glucose<=2.399)            0.025974   \n",
       "925  (0.289<BMI<=0.58, -0.627<BloodPressure<=-0.111...            0.064935   \n",
       "926  (-0.627<BloodPressure<=-0.111, 0.14<Age<=0.396...            0.006494   \n",
       "927  (0.289<BMI<=0.58, 0.14<Age<=0.396, 1, 1.731<Gl...            0.084416   \n",
       "928  (0.289<BMI<=0.58, -0.627<BloodPressure<=-0.111...            0.064935   \n",
       "\n",
       "     consequent support   support  confidence       lift  leverage  conviction  \n",
       "0              0.474026  0.051948    0.800000   1.687671  0.021167    2.629870  \n",
       "1              0.064935  0.051948    0.109589   1.687671  0.021167    1.050150  \n",
       "2              0.474026  0.006494    1.000000   2.109589  0.003415         inf  \n",
       "3              0.474026  0.058442    0.750000   1.582192  0.021504    2.103896  \n",
       "4              0.077922  0.058442    0.123288   1.582192  0.021504    1.051745  \n",
       "..                  ...       ...         ...        ...       ...         ...  \n",
       "924            0.006494  0.006494    0.250000  38.500000  0.006325    1.324675  \n",
       "925            0.006494  0.006494    0.100000  15.400000  0.006072    1.103896  \n",
       "926            0.025974  0.006494    1.000000  38.500000  0.006325         inf  \n",
       "927            0.006494  0.006494    0.076923  11.846154  0.005945    1.076299  \n",
       "928            0.006494  0.006494    0.100000  15.400000  0.006072    1.103896  \n",
       "\n",
       "[929 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "                                        # 10/ len(pred)\n",
    "freq_items = apriori(ohe_df, min_support=(1/len(pred)), use_colnames=True, max_len=3)\n",
    "#print(len(freq_items))\n",
    "#print(freq_items)\n",
    "all_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.02, support_only=False) # 0.7 support_only=False\n",
    "#print(len(all_rules))\n",
    "#print(all_rules)                                                   # 10/ len(pred)\n",
    "freq_items = apriori(ohe_df.loc[ohe_df[pos_label] == 1], min_support=(1/len(pred)), use_colnames=True, max_len=10) # max len 3\n",
    "pos_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.02, support_only=False) # 0.6 support_only=False\n",
    "                                                                    # 10/ len(pred)\n",
    "freq_items = apriori(ohe_df.loc[ohe_df[neg_label] == 1], min_support=(1/len(pred)), use_colnames=True, max_len=10) # max len 3 \n",
    "neg_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.02, support_only=False) # 0.6 support_only=False\n",
    "pos_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47036807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.118506</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.403&lt;BloodPressure&lt;=0.916)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.198052</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.198052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.099026</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.064&lt;Glucose&lt;=1.731)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086039</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-0.111&lt;BloodPressure&lt;=0.403)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.126623</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.126623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.916&lt;BloodPressure&lt;=1.429)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1.687&lt;Insulin&lt;=2.381, 0.396&lt;Glucose&lt;=1.064)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(0.396&lt;Age&lt;=0.653)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(1.429&lt;BloodPressure&lt;=1.943)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116, 1.687&lt;Insulin&lt;=2.381)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(1.687&lt;Insulin&lt;=2.381)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(0.396&lt;Glucose&lt;=1.064)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.826087</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.084416</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-0.051948</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     antecedents consequents   \n",
       "0                         (1.731<Glucose<=2.399)         (1)  \\\n",
       "1                   (0.403<BloodPressure<=0.916)         (1)   \n",
       "2                         (1.064<Glucose<=1.731)         (1)   \n",
       "4                  (-0.111<BloodPressure<=0.403)         (1)   \n",
       "5                   (0.916<BloodPressure<=1.429)         (1)   \n",
       "12  (1.687<Insulin<=2.381, 0.396<Glucose<=1.064)         (1)   \n",
       "13                (-0.627<BloodPressure<=-0.111)         (1)   \n",
       "14                             (0.14<Age<=0.396)         (1)   \n",
       "16                            (0.396<Age<=0.653)         (1)   \n",
       "21                  (1.429<BloodPressure<=1.943)         (1)   \n",
       "37    (-0.372<Age<=-0.116, 1.687<Insulin<=2.381)         (1)   \n",
       "44                        (1.687<Insulin<=2.381)         (1)   \n",
       "45                        (0.396<Glucose<=1.064)         (1)   \n",
       "46                            (-0.116<Age<=0.14)         (1)   \n",
       "47                        (0.992<Insulin<=1.687)         (1)   \n",
       "48                          (-0.372<Age<=-0.116)         (1)   \n",
       "\n",
       "    antecedent support  consequent support   support  confidence      lift   \n",
       "0             0.237013                 0.5  0.237013    1.000000  2.000000  \\\n",
       "1             0.198052                 0.5  0.198052    1.000000  2.000000   \n",
       "2             0.172078                 0.5  0.172078    1.000000  2.000000   \n",
       "4             0.126623                 0.5  0.126623    1.000000  2.000000   \n",
       "5             0.116883                 0.5  0.116883    1.000000  2.000000   \n",
       "12            0.045455                 0.5  0.045455    1.000000  2.000000   \n",
       "13            0.042208                 0.5  0.042208    1.000000  2.000000   \n",
       "14            0.032468                 0.5  0.032468    1.000000  2.000000   \n",
       "16            0.025974                 0.5  0.025974    1.000000  2.000000   \n",
       "21            0.016234                 0.5  0.016234    1.000000  2.000000   \n",
       "37            0.006494                 0.5  0.006494    1.000000  2.000000   \n",
       "44            0.077922                 0.5  0.071429    0.916667  1.833333   \n",
       "45            0.074675                 0.5  0.068182    0.913043  1.826087   \n",
       "46            0.087662                 0.5  0.038961    0.444444  0.888889   \n",
       "47            0.084416                 0.5  0.019481    0.230769  0.461538   \n",
       "48            0.142857                 0.5  0.019481    0.136364  0.272727   \n",
       "\n",
       "    leverage  conviction  \n",
       "0   0.118506         inf  \n",
       "1   0.099026         inf  \n",
       "2   0.086039         inf  \n",
       "4   0.063312         inf  \n",
       "5   0.058442         inf  \n",
       "12  0.022727         inf  \n",
       "13  0.021104         inf  \n",
       "14  0.016234         inf  \n",
       "16  0.012987         inf  \n",
       "21  0.008117         inf  \n",
       "37  0.003247         inf  \n",
       "44  0.032468    6.000000  \n",
       "45  0.030844    5.750000  \n",
       "46 -0.004870    0.900000  \n",
       "47 -0.022727    0.650000  \n",
       "48 -0.051948    0.578947  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = all_rules[all_rules['consequents'] == {pos_label}]\n",
    "positive = positive[positive['confidence'] >= 0.1] # confidence == 1\n",
    "positive = positive.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "positive = positive.reset_index(drop=True)\n",
    "for i in positive.index:\n",
    "    new_rule = positive.loc[[i]]['antecedents'].values[0]\n",
    "    \n",
    "    for seen_rule in seen:\n",
    "        if seen_rule.issubset(new_rule):#new_rule.issubset(seen_rule) or seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add(new_rule)\n",
    "\n",
    "positive.drop(positive.index[indexes_to_drop], inplace=True )\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83958b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-1.097&lt;Insulin&lt;=-0.398)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-0.583&lt;BMI&lt;=-0.292)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-1.074&lt;DiabetesPedigreeFunction&lt;=-0.864)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.105519</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-0.839&lt;SkinThickness&lt;=-0.543)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.185065</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.185065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092532</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-0.629&lt;Age&lt;=-0.372)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(-0.972&lt;Pregnancies&lt;=-0.778)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(-0.543&lt;SkinThickness&lt;=-0.249)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(-0.778&lt;Pregnancies&lt;=-0.583)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086039</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(-0.864&lt;DiabetesPedigreeFunction&lt;=-0.655)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(-0.292&lt;BMI&lt;=-0.00171)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.081169</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(-0.249&lt;SkinThickness&lt;=0.0455)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(-1.167&lt;Pregnancies&lt;=-0.972)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(-0.00171&lt;BMI&lt;=0.289)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(-1.283&lt;DiabetesPedigreeFunction&lt;=-1.074)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(0.297&lt;Insulin&lt;=0.992)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>(-0.655&lt;DiabetesPedigreeFunction&lt;=-0.445)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>(-0.583&lt;Pregnancies&lt;=-0.388)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(0.0455&lt;SkinThickness&lt;=0.34)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>(-1.363&lt;Pregnancies&lt;=-1.167)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687, -0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>(-1.493&lt;DiabetesPedigreeFunction&lt;=-1.283)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>(-0.875&lt;BMI&lt;=-0.583)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>(-0.942&lt;Glucose&lt;=-0.271)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>(-0.271&lt;Glucose&lt;=0.396)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.084416</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>(-0.398&lt;Insulin&lt;=0.297)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>(0)</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    antecedents consequents   \n",
       "0                      (-1.097<Insulin<=-0.398)         (0)  \\\n",
       "1                          (-0.583<BMI<=-0.292)         (0)   \n",
       "2     (-1.074<DiabetesPedigreeFunction<=-0.864)         (0)   \n",
       "3                (-0.839<SkinThickness<=-0.543)         (0)   \n",
       "4                          (-0.629<Age<=-0.372)         (0)   \n",
       "5                  (-0.972<Pregnancies<=-0.778)         (0)   \n",
       "6                (-0.543<SkinThickness<=-0.249)         (0)   \n",
       "7                  (-0.778<Pregnancies<=-0.583)         (0)   \n",
       "8     (-0.864<DiabetesPedigreeFunction<=-0.655)         (0)   \n",
       "9                        (-0.292<BMI<=-0.00171)         (0)   \n",
       "17               (-0.249<SkinThickness<=0.0455)         (0)   \n",
       "19                 (-1.167<Pregnancies<=-0.972)         (0)   \n",
       "26                        (-0.00171<BMI<=0.289)         (0)   \n",
       "32    (-1.283<DiabetesPedigreeFunction<=-1.074)         (0)   \n",
       "51                       (0.297<Insulin<=0.992)         (0)   \n",
       "60    (-0.655<DiabetesPedigreeFunction<=-0.445)         (0)   \n",
       "108                (-0.583<Pregnancies<=-0.388)         (0)   \n",
       "121                (0.0455<SkinThickness<=0.34)         (0)   \n",
       "131                (-1.363<Pregnancies<=-1.167)         (0)   \n",
       "136  (0.992<Insulin<=1.687, -0.372<Age<=-0.116)         (0)   \n",
       "141   (-1.493<DiabetesPedigreeFunction<=-1.283)         (0)   \n",
       "142                        (-0.875<BMI<=-0.583)         (0)   \n",
       "154                    (-0.942<Glucose<=-0.271)         (0)   \n",
       "155                     (-0.271<Glucose<=0.396)         (0)   \n",
       "191                        (-0.372<Age<=-0.116)         (0)   \n",
       "192                           (0.289<BMI<=0.58)         (0)   \n",
       "193                      (0.992<Insulin<=1.687)         (0)   \n",
       "194                     (-0.398<Insulin<=0.297)         (0)   \n",
       "195                          (-0.116<Age<=0.14)         (0)   \n",
       "\n",
       "     antecedent support  consequent support   support  confidence      lift   \n",
       "0              0.233766                 0.5  0.233766    1.000000  2.000000  \\\n",
       "1              0.220779                 0.5  0.220779    1.000000  2.000000   \n",
       "2              0.211039                 0.5  0.211039    1.000000  2.000000   \n",
       "3              0.185065                 0.5  0.185065    1.000000  2.000000   \n",
       "4              0.181818                 0.5  0.181818    1.000000  2.000000   \n",
       "5              0.178571                 0.5  0.178571    1.000000  2.000000   \n",
       "6              0.175325                 0.5  0.175325    1.000000  2.000000   \n",
       "7              0.172078                 0.5  0.172078    1.000000  2.000000   \n",
       "8              0.165584                 0.5  0.165584    1.000000  2.000000   \n",
       "9              0.162338                 0.5  0.162338    1.000000  2.000000   \n",
       "17             0.116883                 0.5  0.116883    1.000000  2.000000   \n",
       "19             0.110390                 0.5  0.110390    1.000000  2.000000   \n",
       "26             0.087662                 0.5  0.087662    1.000000  2.000000   \n",
       "32             0.071429                 0.5  0.071429    1.000000  2.000000   \n",
       "51             0.051948                 0.5  0.051948    1.000000  2.000000   \n",
       "60             0.042208                 0.5  0.042208    1.000000  2.000000   \n",
       "108            0.022727                 0.5  0.022727    1.000000  2.000000   \n",
       "121            0.016234                 0.5  0.016234    1.000000  2.000000   \n",
       "131            0.012987                 0.5  0.012987    1.000000  2.000000   \n",
       "136            0.012987                 0.5  0.012987    1.000000  2.000000   \n",
       "141            0.009740                 0.5  0.009740    1.000000  2.000000   \n",
       "142            0.009740                 0.5  0.009740    1.000000  2.000000   \n",
       "154            0.006494                 0.5  0.006494    1.000000  2.000000   \n",
       "155            0.006494                 0.5  0.006494    1.000000  2.000000   \n",
       "191            0.142857                 0.5  0.123377    0.863636  1.727273   \n",
       "192            0.019481                 0.5  0.016234    0.833333  1.666667   \n",
       "193            0.084416                 0.5  0.064935    0.769231  1.538462   \n",
       "194            0.009740                 0.5  0.006494    0.666667  1.333333   \n",
       "195            0.087662                 0.5  0.048701    0.555556  1.111111   \n",
       "\n",
       "     leverage  conviction  \n",
       "0    0.116883         inf  \n",
       "1    0.110390         inf  \n",
       "2    0.105519         inf  \n",
       "3    0.092532         inf  \n",
       "4    0.090909         inf  \n",
       "5    0.089286         inf  \n",
       "6    0.087662         inf  \n",
       "7    0.086039         inf  \n",
       "8    0.082792         inf  \n",
       "9    0.081169         inf  \n",
       "17   0.058442         inf  \n",
       "19   0.055195         inf  \n",
       "26   0.043831         inf  \n",
       "32   0.035714         inf  \n",
       "51   0.025974         inf  \n",
       "60   0.021104         inf  \n",
       "108  0.011364         inf  \n",
       "121  0.008117         inf  \n",
       "131  0.006494         inf  \n",
       "136  0.006494         inf  \n",
       "141  0.004870         inf  \n",
       "142  0.004870         inf  \n",
       "154  0.003247         inf  \n",
       "155  0.003247         inf  \n",
       "191  0.051948    3.666667  \n",
       "192  0.006494    3.000000  \n",
       "193  0.022727    2.166667  \n",
       "194  0.001623    1.500000  \n",
       "195  0.004870    1.125000  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = all_rules[all_rules['consequents'] == {neg_label}]\n",
    "negative = negative[negative['confidence'] >= 0.1] # confidence == 1\n",
    "\n",
    "negative = negative.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "negative = negative.reset_index(drop=True)\n",
    "for i in negative.index:\n",
    "    new_rule = negative.loc[[i]]['antecedents'].values[0]\n",
    "    \n",
    "    for seen_rule in seen:\n",
    "        if seen_rule.issubset(new_rule):#new_rule.issubset(seen_rule) or seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add(new_rule)\n",
    "\n",
    "negative.drop(negative.index[indexes_to_drop], inplace=True )\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f57889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>label</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>antecedent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.731&lt;Glucose&lt;=2.399)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(-1.097&lt;Insulin&lt;=-0.398)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(-0.583&lt;BMI&lt;=-0.292)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(-1.074&lt;DiabetesPedigreeFunction&lt;=-0.864)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.403&lt;BloodPressure&lt;=0.916)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(-0.839&lt;SkinThickness&lt;=-0.543)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(-0.629&lt;Age&lt;=-0.372)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(-0.972&lt;Pregnancies&lt;=-0.778)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(-0.543&lt;SkinThickness&lt;=-0.249)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.064&lt;Glucose&lt;=1.731)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(-0.778&lt;Pregnancies&lt;=-0.583)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(-0.864&lt;DiabetesPedigreeFunction&lt;=-0.655)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(-0.292&lt;BMI&lt;=-0.00171)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-0.111&lt;BloodPressure&lt;=0.403)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.916&lt;BloodPressure&lt;=1.429)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(-0.249&lt;SkinThickness&lt;=0.0455)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(-1.167&lt;Pregnancies&lt;=-0.972)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(-0.00171&lt;BMI&lt;=0.289)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(-1.283&lt;DiabetesPedigreeFunction&lt;=-1.074)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1.687&lt;Insulin&lt;=2.381)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.077922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0.396&lt;Glucose&lt;=1.064)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.074675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.084416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(0.297&lt;Insulin&lt;=0.992)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.087662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1.687&lt;Insulin&lt;=2.381, 0.396&lt;Glucose&lt;=1.064)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(-0.655&lt;DiabetesPedigreeFunction&lt;=-0.445)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(-0.116&lt;Age&lt;=0.14)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.087662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.14&lt;Age&lt;=0.396)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.396&lt;Age&lt;=0.653)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(-0.583&lt;Pregnancies&lt;=-0.388)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.084416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1.429&lt;BloodPressure&lt;=1.943)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(0.0455&lt;SkinThickness&lt;=0.34)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(0.289&lt;BMI&lt;=0.58)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.019481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(0.992&lt;Insulin&lt;=1.687, -0.372&lt;Age&lt;=-0.116)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(-1.363&lt;Pregnancies&lt;=-1.167)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(-1.493&lt;DiabetesPedigreeFunction&lt;=-1.283)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(-0.875&lt;BMI&lt;=-0.583)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(-0.372&lt;Age&lt;=-0.116, 1.687&lt;Insulin&lt;=2.381)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(-0.942&lt;Glucose&lt;=-0.271)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(-0.271&lt;Glucose&lt;=0.396)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(-0.398&lt;Insulin&lt;=0.297)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         itemset label  num-items   support   \n",
       "0                         (1.731<Glucose<=2.399)     1          1  0.237013  \\\n",
       "16                      (-1.097<Insulin<=-0.398)     0          1  0.233766   \n",
       "17                          (-0.583<BMI<=-0.292)     0          1  0.220779   \n",
       "18     (-1.074<DiabetesPedigreeFunction<=-0.864)     0          1  0.211039   \n",
       "1                   (0.403<BloodPressure<=0.916)     1          1  0.198052   \n",
       "19                (-0.839<SkinThickness<=-0.543)     0          1  0.185065   \n",
       "20                          (-0.629<Age<=-0.372)     0          1  0.181818   \n",
       "21                  (-0.972<Pregnancies<=-0.778)     0          1  0.178571   \n",
       "22                (-0.543<SkinThickness<=-0.249)     0          1  0.175325   \n",
       "2                         (1.064<Glucose<=1.731)     1          1  0.172078   \n",
       "23                  (-0.778<Pregnancies<=-0.583)     0          1  0.172078   \n",
       "24     (-0.864<DiabetesPedigreeFunction<=-0.655)     0          1  0.165584   \n",
       "25                        (-0.292<BMI<=-0.00171)     0          1  0.162338   \n",
       "3                  (-0.111<BloodPressure<=0.403)     1          1  0.126623   \n",
       "40                          (-0.372<Age<=-0.116)     0          1  0.123377   \n",
       "4                   (0.916<BloodPressure<=1.429)     1          1  0.116883   \n",
       "26                (-0.249<SkinThickness<=0.0455)     0          1  0.116883   \n",
       "27                  (-1.167<Pregnancies<=-0.972)     0          1  0.110390   \n",
       "28                         (-0.00171<BMI<=0.289)     0          1  0.087662   \n",
       "29     (-1.283<DiabetesPedigreeFunction<=-1.074)     0          1  0.071429   \n",
       "11                        (1.687<Insulin<=2.381)     1          1  0.071429   \n",
       "12                        (0.396<Glucose<=1.064)     1          1  0.068182   \n",
       "42                        (0.992<Insulin<=1.687)     0          1  0.064935   \n",
       "30                        (0.297<Insulin<=0.992)     0          1  0.051948   \n",
       "44                            (-0.116<Age<=0.14)     0          1  0.048701   \n",
       "5   (1.687<Insulin<=2.381, 0.396<Glucose<=1.064)     1          2  0.045455   \n",
       "6                 (-0.627<BloodPressure<=-0.111)     1          1  0.042208   \n",
       "31     (-0.655<DiabetesPedigreeFunction<=-0.445)     0          1  0.042208   \n",
       "13                            (-0.116<Age<=0.14)     1          1  0.038961   \n",
       "7                              (0.14<Age<=0.396)     1          1  0.032468   \n",
       "8                             (0.396<Age<=0.653)     1          1  0.025974   \n",
       "32                  (-0.583<Pregnancies<=-0.388)     0          1  0.022727   \n",
       "14                        (0.992<Insulin<=1.687)     1          1  0.019481   \n",
       "15                          (-0.372<Age<=-0.116)     1          1  0.019481   \n",
       "9                   (1.429<BloodPressure<=1.943)     1          1  0.016234   \n",
       "33                  (0.0455<SkinThickness<=0.34)     0          1  0.016234   \n",
       "41                             (0.289<BMI<=0.58)     0          1  0.016234   \n",
       "35    (0.992<Insulin<=1.687, -0.372<Age<=-0.116)     0          2  0.012987   \n",
       "34                  (-1.363<Pregnancies<=-1.167)     0          1  0.012987   \n",
       "36     (-1.493<DiabetesPedigreeFunction<=-1.283)     0          1  0.009740   \n",
       "37                          (-0.875<BMI<=-0.583)     0          1  0.009740   \n",
       "10    (-0.372<Age<=-0.116, 1.687<Insulin<=2.381)     1          2  0.006494   \n",
       "38                      (-0.942<Glucose<=-0.271)     0          1  0.006494   \n",
       "39                       (-0.271<Glucose<=0.396)     0          1  0.006494   \n",
       "43                       (-0.398<Insulin<=0.297)     0          1  0.006494   \n",
       "\n",
       "    confidence  antecedent support  \n",
       "0     1.000000            0.237013  \n",
       "16    1.000000            0.233766  \n",
       "17    1.000000            0.220779  \n",
       "18    1.000000            0.211039  \n",
       "1     1.000000            0.198052  \n",
       "19    1.000000            0.185065  \n",
       "20    1.000000            0.181818  \n",
       "21    1.000000            0.178571  \n",
       "22    1.000000            0.175325  \n",
       "2     1.000000            0.172078  \n",
       "23    1.000000            0.172078  \n",
       "24    1.000000            0.165584  \n",
       "25    1.000000            0.162338  \n",
       "3     1.000000            0.126623  \n",
       "40    0.863636            0.142857  \n",
       "4     1.000000            0.116883  \n",
       "26    1.000000            0.116883  \n",
       "27    1.000000            0.110390  \n",
       "28    1.000000            0.087662  \n",
       "29    1.000000            0.071429  \n",
       "11    0.916667            0.077922  \n",
       "12    0.913043            0.074675  \n",
       "42    0.769231            0.084416  \n",
       "30    1.000000            0.051948  \n",
       "44    0.555556            0.087662  \n",
       "5     1.000000            0.045455  \n",
       "6     1.000000            0.042208  \n",
       "31    1.000000            0.042208  \n",
       "13    0.444444            0.087662  \n",
       "7     1.000000            0.032468  \n",
       "8     1.000000            0.025974  \n",
       "32    1.000000            0.022727  \n",
       "14    0.230769            0.084416  \n",
       "15    0.136364            0.142857  \n",
       "9     1.000000            0.016234  \n",
       "33    1.000000            0.016234  \n",
       "41    0.833333            0.019481  \n",
       "35    1.000000            0.012987  \n",
       "34    1.000000            0.012987  \n",
       "36    1.000000            0.009740  \n",
       "37    1.000000            0.009740  \n",
       "10    1.000000            0.006494  \n",
       "38    1.000000            0.006494  \n",
       "39    1.000000            0.006494  \n",
       "43    0.666667            0.009740  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive['num-items'] = positive['antecedents'].map(lambda x: len(x))\n",
    "negative['num-items'] = negative['antecedents'].map(lambda x: len(x))\n",
    "positive['consequents'] = positive['consequents'].map(lambda x: pos_label)\n",
    "negative['consequents'] = negative['consequents'].map(lambda x: neg_label)\n",
    "\n",
    "both = pd.concat([positive, negative], ignore_index=True)\n",
    "\n",
    "#both = positive.append(negative, ignore_index=True)\n",
    "\n",
    "discr_rules = both[['antecedents', 'consequents', 'num-items', 'support', 'confidence', 'antecedent support']].sort_values(\n",
    "    ['support', 'confidence', 'num-items'], ascending=[False, False, False])\n",
    "\n",
    "discr_rules = discr_rules.rename(columns={\"antecedents\": \"itemset\", \"consequents\": \"label\"})\n",
    "\n",
    "discr_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_positive = pos_rules[pos_rules['antecedents'] == {pos_label}]\n",
    "#rev_positive = pos_rules[pos_rules['consequents'] == {pos_label}] \n",
    "rev_positive = rev_positive[rev_positive['confidence'] >= 0.7]\n",
    "rev_positive = rev_positive.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "rev_positive = rev_positive.reset_index(drop=True)\n",
    "for i in rev_positive.index:\n",
    "    new_rule = rev_positive.loc[[i]]['consequents'].values[0]\n",
    "    \n",
    "    for seen_rule, indx in seen:\n",
    "        if seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add((new_rule, i))\n",
    "\n",
    "rev_positive.drop(rev_positive.index[indexes_to_drop], inplace=True )\n",
    "\n",
    "\n",
    "\n",
    "rev_negative = neg_rules[neg_rules['antecedents'] == {neg_label}]\n",
    "#rev_negative = neg_rules[neg_rules['consequents'] == {neg_label}]\n",
    "rev_negative = rev_negative[rev_negative['confidence'] >= 0.7]\n",
    "rev_negative = rev_negative.sort_values(['confidence', 'support'], ascending=[False, False])\n",
    "\n",
    "seen = set()\n",
    "dropped = set()\n",
    "indexes_to_drop = []\n",
    "\n",
    "rev_negative = rev_negative.reset_index(drop=True)\n",
    "for i in rev_negative.index:\n",
    "    new_rule = rev_negative.loc[[i]]['consequents'].values[0]\n",
    "    \n",
    "    for seen_rule, indx in seen:\n",
    "        if seen_rule.issubset(new_rule):\n",
    "            indexes_to_drop.append(i)\n",
    "            break\n",
    "    else:\n",
    "        seen.add((new_rule, i))\n",
    "\n",
    "rev_negative.drop(rev_negative.index[indexes_to_drop], inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01f772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>itemset</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>consequent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, itemset, num-items, support, confidence, consequent support]\n",
       "Index: []"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_positive['num-items'] = rev_positive['consequents'].map(lambda x: len(x))\n",
    "rev_negative['num-items'] = rev_negative['consequents'].map(lambda x: len(x))\n",
    "rev_positive['antecedents'] = rev_positive['antecedents'].map(lambda x: pos_label)\n",
    "rev_negative['antecedents'] = rev_negative['antecedents'].map(lambda x: neg_label)\n",
    "\n",
    "#rev_both = rev_positive.append(rev_negative, ignore_index=True)\n",
    "rev_both = pd.concat([rev_positive, rev_negative], ignore_index=True)\n",
    "\n",
    "chr_rules = rev_both[['antecedents', 'consequents', 'num-items', 'support', \n",
    "                          'confidence', 'consequent support']].sort_values(\n",
    "    ['support', 'confidence', 'num-items'], ascending=[False, False, False])\n",
    "\n",
    "chr_rules = chr_rules.rename(columns={\"antecedents\": \"label\", \"consequents\": \"itemset\"})\n",
    "\n",
    "chr_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eada9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom rules_model import *\\n\\ndev_pred = model.predict(X_test.to(\"cuda:0\"))\\nrules_model = RulesModel(ohe_df, discr_rules, X_test_DF, pos_label, neg_label)\\n\\ntest_pred = model.predict(X_train.to(\"cuda:0\"))\\nrules_test_sol = rules_model.eval_rules(X_test_DF, test_pred, alpha=10, beta =1, decision_thr=0.97)\\n'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from rules_model import *\n",
    "\n",
    "dev_pred = model.predict(X_test.to(\"cuda:0\"))\n",
    "rules_model = RulesModel(ohe_df, discr_rules, X_test_DF, pos_label, neg_label)\n",
    "\n",
    "test_pred = model.predict(X_train.to(\"cuda:0\"))\n",
    "rules_test_sol = rules_model.eval_rules(X_test_DF, test_pred, alpha=10, beta =1, decision_thr=0.97)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb792e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrules_model = RulesModel(ohe_df, chr_rules, X_test_DF, pos_label, neg_label)\\n\\ntest_pred = model.predict(X_test)\\nprint(type(test_pred))\\nprint(type(X_test))\\nrules_test_sol = rules_model.eval_rules(X_test, test_pred, alpha=30, beta=1, decision_thr=0.041)\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rules_model = RulesModel(ohe_df, chr_rules, X_test_DF, pos_label, neg_label)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "print(type(test_pred))\n",
    "print(type(X_test))\n",
    "rules_test_sol = rules_model.eval_rules(X_test, test_pred, alpha=30, beta=1, decision_thr=0.041)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c88d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import eval\n",
    "\n",
    "#model.load_state_dict(\"/home/rosario/explainable/Bachelor/Models/finalModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dad76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>label</th>\n",
       "      <th>num-items</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>antecedent support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1.687&lt;Insulin&lt;=2.381, 0.396&lt;Glucose&lt;=1.064)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(-0.627&lt;BloodPressure&lt;=-0.111)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        itemset label  num-items   support   \n",
       "5  (1.687<Insulin<=2.381, 0.396<Glucose<=1.064)     1          2  0.045455  \\\n",
       "6                (-0.627<BloodPressure<=-0.111)     1          1  0.042208   \n",
       "\n",
       "   confidence  antecedent support  \n",
       "5         1.0            0.045455  \n",
       "6         1.0            0.042208  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discr_rules\n",
    "discr_rules1 =  discr_rules.loc[5:6]\n",
    "discr_rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ca66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('1.731', 'Glucose', '2.399')], [('-1.097', 'Insulin', '-0.398')], [('-0.583', 'BMI', '-0.292')], [('-1.074', 'DiabetesPedigreeFunction', '-0.864')], [('0.403', 'BloodPressure', '0.916')], [('-0.839', 'SkinThickness', '-0.543')], [('-0.629', 'Age', '-0.372')], [('-0.972', 'Pregnancies', '-0.778')], [('-0.543', 'SkinThickness', '-0.249')], [('1.064', 'Glucose', '1.731')], [('-0.778', 'Pregnancies', '-0.583')], [('-0.864', 'DiabetesPedigreeFunction', '-0.655')], [('-0.292', 'BMI', '-0.00171')], [('-0.111', 'BloodPressure', '0.403')], [('-0.372', 'Age', '-0.116')], [('0.916', 'BloodPressure', '1.429')], [('-0.249', 'SkinThickness', '0.0455')], [('-1.167', 'Pregnancies', '-0.972')], [('-0.00171', 'BMI', '0.289')], [('-1.283', 'DiabetesPedigreeFunction', '-1.074')], [('1.687', 'Insulin', '2.381')], [('0.396', 'Glucose', '1.064')], [('0.992', 'Insulin', '1.687')], [('0.297', 'Insulin', '0.992')], [('-0.116', 'Age', '0.14')], [('1.687', 'Insulin', '2.381'), ('0.396', 'Glucose', '1.064')], [('-0.627', 'BloodPressure', '-0.111')], [('-0.655', 'DiabetesPedigreeFunction', '-0.445')], [('-0.116', 'Age', '0.14')], [('0.14', 'Age', '0.396')], [('0.396', 'Age', '0.653')], [('-0.583', 'Pregnancies', '-0.388')], [('0.992', 'Insulin', '1.687')], [('-0.372', 'Age', '-0.116')], [('1.429', 'BloodPressure', '1.943')], [('0.0455', 'SkinThickness', '0.34')], [('0.289', 'BMI', '0.58')], [('0.992', 'Insulin', '1.687'), ('-0.372', 'Age', '-0.116')], [('-1.363', 'Pregnancies', '-1.167')], [('-1.493', 'DiabetesPedigreeFunction', '-1.283')], [('-0.875', 'BMI', '-0.583')], [('-0.372', 'Age', '-0.116'), ('1.687', 'Insulin', '2.381')], [('-0.942', 'Glucose', '-0.271')], [('-0.271', 'Glucose', '0.396')], [('-0.398', 'Insulin', '0.297')]]\n",
      "[[0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, 0, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, 0, -1, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], [-1, -1, 1, 1, -1, 1, -1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, 1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, 1, -1, 0, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, 1, 0, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, 0, -1, 1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, -1, 1, -1, 0, -1, -1, -1, 0, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, 0, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, 1, 0, -1, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, 0, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, -1, 1, 1, 0, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, 1, -1, -1, 0, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 0, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, -1, -1, 1, -1, -1, -1, 0, 1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, 1, -1, 0, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, -1, 1, 0, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, 1, -1, 0, -1, -1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 0, 1, -1, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, 0, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, 1, 1, 0, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1], [0, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, 0, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, -1, -1, 1, -1, -1, -1, 0, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, 1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, 1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, 1, -1, -1, 0, -1, -1, 1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 0, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 0, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, -1, -1, 1, 0, -1, -1, -1, 0, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, 0, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, -1, 1, -1, 0, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1], [0, -1, 1, 1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, 0, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, -1, 1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, 1, -1, 0, -1, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, -1, 1, -1, 0, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1], [-1, 1, -1, 1, -1, -1, -1, -1, -1, 0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1], [-1, -1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, 0, -1, 1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, 0, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, 0, -1, 1, 1, 1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, 1, 0, 0, -1, -1, 1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, 0, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, 0, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, 0, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1], [-1, -1, 1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 0, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, 1, -1, -1, 1, 1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, 1, 1, -1, -1, 0, -1, -1, 1, -1, -1, 0, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, 1, 0, 1, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 0, -1, -1, -1, 1, -1, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, 0, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [0, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]\n",
      "[0, 0.625, 0.6617647058823529, 0.6923076923076923, 0, 0.7894736842105263, 0.8035714285714286, 0.8181818181818182, 0.8333333333333334, 0, 0.8490566037735849, 0.8823529411764706, 0.9, 0, 1.0, 0, 1.25, 1.3235294117647058, 1.6666666666666667, 2.0454545454545454, 0, 0, 1.3636363636363635, 2.8125, 1.3235294117647058, 0, 0, 3.4615384615384617, 0, 0, 0, 6.428571428571429, 0, 0, 0, 9.0, 7.5, 6.428571428571429, 11.25, 15.0, 15.0, 0, 22.5, 15.0, 15.0]\n",
      "[0.6164383561643836, 0.625, 0.6617647058823529, 0.6923076923076923, 0.7377049180327869, 0.7894736842105263, 0.8035714285714286, 0.8181818181818182, 0.8333333333333334, 0.8490566037735849, 0.8490566037735849, 0.8823529411764706, 0.9, 1.1538461538461537, 1.0, 1.25, 1.25, 1.3235294117647058, 1.6666666666666667, 2.0454545454545454, 1.5517241379310345, 1.9565217391304348, 1.3636363636363635, 2.8125, 1.3235294117647058, 2.142857142857143, 3.4615384615384617, 3.4615384615384617, 1.3235294117647058, 4.5, 5.0, 6.428571428571429, 1.3636363636363635, 1.0, 9.0, 9.0, 7.5, 6.428571428571429, 11.25, 15.0, 15.0, 9.0, 22.5, 15.0, 15.0]\n",
      "1.0\n",
      "45\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "featureDict= {'Pregnancies':0, 'Glucose':1, 'BloodPressure':2, 'SkinThickness':3, 'Insulin':4,\n",
    "       'BMI':5, 'DiabetesPedigreeFunction':6, 'Age':7}\n",
    "\n",
    "rulesList =discr_rules[\"itemset\"].to_list()\n",
    "rulesList = [set(frozenset) for frozenset in rulesList]\n",
    "\n",
    "labelList_rules = discr_rules[\"label\"].apply(lambda x: ', '.join(list(x))).astype(\"unicode\")\n",
    "labelList_rules = [set(frozenset).pop() for frozenset in labelList_rules]\n",
    "\n",
    "# Regular expression pattern\n",
    "pattern = r\"([+-]?\\d+\\.\\d+)(<\\w+<=)([+-]?\\d+\\.\\d+)\"\n",
    "\n",
    "#bounds = re.findall(r\"([+-]?\\d+\\.\\d+)([<=>])([+-]?\\d+\\.\\d+)\", set_item)  # Extract bounds and category\n",
    "\n",
    "\n",
    "# Filter out upper bound, lower bound, and category for each set\n",
    "filtered_list = []\n",
    "for set_item in rulesList:\n",
    "    set_filtered = []\n",
    "    for item in set_item:\n",
    "        matches = re.findall(pattern, item)\n",
    "        if matches:\n",
    "            lower_bound, feature, upper_bound = matches[0]\n",
    "            set_filtered.append((lower_bound, feature[1:-2], upper_bound))\n",
    "    filtered_list.append(set_filtered)\n",
    "\n",
    "print(filtered_list)\n",
    "\n",
    "# meeeheeesrse\n",
    "X_testList = []\n",
    "y_testList = [] \n",
    "#print(testData[1])\n",
    "for inputs, lables in testloader:\n",
    "    X_testList.extend(inputs)\n",
    "    y_testList.extend(lables)\n",
    "\n",
    "pred = model.predict(X_test.to(\"cuda:0\"))\n",
    "\n",
    "def applyRulesOnData(data,predictions, rules, rulesLables, featureDict):\n",
    "    \"\"\"\n",
    "    data: List\n",
    "    predictions: List\n",
    "    rules : List \n",
    "    rulesLables : List\n",
    "\n",
    "    \"\"\"\n",
    "    predictionList = []  \n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        tempPredictionList = []  \n",
    "        rulesComplexityList = []\n",
    "        for i in range(len(rules)): \n",
    "            # for all rules per sample # num samples * num rules\n",
    "                                            # only works for one \n",
    "            #print(filtered_list[i][0])\n",
    "\n",
    "            conditionsAreMet = False\n",
    "            rulesComplexityList.append(len(rules[i]))\n",
    "            for k in range(len(rules[i])):\n",
    "                #print(\"K:\")\n",
    "                #print(k)\n",
    "                \n",
    "                \n",
    "                lowerBound, feature, upperBound = rules[i][k]\n",
    "                #print(feature)\n",
    "                #print()\n",
    "                #print(X_testList[i][featureDict[feature]])\n",
    "                if float(lowerBound) < data[j][featureDict[feature]] <= float(upperBound):\n",
    "                    conditionsAreMet = True\n",
    "                    # Rule is apicable\n",
    "\n",
    "                else:\n",
    "                    # rules is not aplicable      \n",
    "                    tempPredictionList.append(-1)\n",
    "                    conditionsAreMet = False\n",
    "                    break\n",
    "            #print(\"k END\")  \n",
    "            if conditionsAreMet == True:\n",
    "                if predictions[j] ==  int(rulesLables[i]):\n",
    "                    # explaination model prediction is the same as trained Model prediction\n",
    "                    tempPredictionList.append(1)\n",
    "                elif predictions[j] != int(rulesLables[i]):\n",
    "                    # explaination model prediction not the same as trained Model prediction\n",
    "                    tempPredictionList.append(0)\n",
    "\n",
    "        predictionList.append(tempPredictionList)\n",
    "    return predictionList, rulesComplexityList\n",
    "\n",
    "predictionList, rulesComplexityList = applyRulesOnData(X_testList,pred, filtered_list, labelList_rules, featureDict)\n",
    "predictionList\n",
    "\n",
    "def metricCalc(predictionList):\n",
    "    \n",
    "    isCoverdList = []\n",
    "    correctPredictedList = [] \n",
    "    for i in predictionList:\n",
    "        isCovered = False\n",
    "        for j in i:\n",
    "            if j == 0 or j ==1:\n",
    "                isCovered = True\n",
    "                isCoverdList.append(1) # wird von einer Rule abgedeckt\n",
    "                break\n",
    "        if not isCovered:\n",
    "           isCoverdList.append(-1)\n",
    "    return isCoverdList\n",
    "isCoverdList = metricCalc(predictionList)\n",
    "\n",
    "coverage = isCoverdList.count(1) /len(isCoverdList) # instances covered by global explanation set  \n",
    "\n",
    "\n",
    "def rulePrecisionAndSupport(predictionList): \n",
    "    \n",
    "    # recision of an applicable rule on test instances(precision)\n",
    "    # AND how many instances does a rule cover (Support)\n",
    "    \n",
    "    predictionList_transposed =  np.array(predictionList).transpose()\n",
    "    rulePrecisionList = [] \n",
    "    ruleSupportList = [] \n",
    "    for i in predictionList_transposed:\n",
    "        tempCorrectClassified = list(i).count(1)\n",
    "        tempFalseClassified =   list(i).count(0)\n",
    "        #tempNotAplicable =     list(i).count(0) \n",
    "\n",
    "        try:\n",
    "            rulePrecisionList.append(len(predictionList_transposed) / tempCorrectClassified)\n",
    "        except ZeroDivisionError:\n",
    "            #print(\"ZeroDivisionError\")\n",
    "            rulePrecisionList.append(0)\n",
    "        try:\n",
    "            ruleSupportList.append(len(predictionList_transposed)/ (tempCorrectClassified + tempFalseClassified))\n",
    "        except ZeroDivisionError:\n",
    "            #print(\"ZeroDivisionError\")\n",
    "            rulePrecisionList.append(0)\n",
    "        \n",
    "    \n",
    "    return rulePrecisionList, ruleSupportList\n",
    "rulePrecisionList, ruleSupportList = rulePrecisionAndSupport(predictionList)\n",
    "\n",
    "generatedRules = (len(rulesList))\n",
    "\n",
    "print(predictionList)\n",
    "print(rulePrecisionList)\n",
    "print(ruleSupportList)\n",
    "print(coverage)\n",
    "print(generatedRules)\n",
    "print(rulesComplexityList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afd23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
